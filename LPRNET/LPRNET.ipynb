{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ORnDjHVXwn06"
   },
   "source": [
    "# 网络构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2dsfY_1MrYOv"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class small_basic_block(nn.Module):\n",
    "    def __init__(self, ch_in, ch_out):\n",
    "        super(small_basic_block, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(ch_in, ch_out // 4, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(ch_out // 4, ch_out // 4, kernel_size=(3, 1), padding=(1, 0)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(ch_out // 4, ch_out // 4, kernel_size=(1, 3), padding=(0, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(ch_out // 4, ch_out, kernel_size=1),\n",
    "            )\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "class LPRNet(nn.Module):\n",
    "    def __init__(self, class_num, dropout_rate=0.5):\n",
    "        super(LPRNet, self).__init__()\n",
    "        self.backbone = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1), # 0\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.ReLU(),  # 2\n",
    "            nn.MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 1, 1)),\n",
    "            small_basic_block(ch_in=64, ch_out=128),    # *** 4 ***\n",
    "            nn.BatchNorm2d(num_features=128),\n",
    "            nn.ReLU(),  # 6\n",
    "            nn.MaxPool3d(kernel_size=(1, 3, 3), stride=(2, 1, 2)),\n",
    "            small_basic_block(ch_in=64, ch_out=256),   # 8\n",
    "            nn.BatchNorm2d(num_features=256),\n",
    "            nn.ReLU(),  # 10\n",
    "            small_basic_block(ch_in=256, ch_out=256),   # *** 11 ***\n",
    "            nn.BatchNorm2d(num_features=256),   # 12\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=(1, 3, 3), stride=(4, 1, 2)),  # 14\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Conv2d(in_channels=64, out_channels=256, kernel_size=(1, 4), stride=1),  # 16\n",
    "            nn.BatchNorm2d(num_features=256),\n",
    "            nn.ReLU(),  # 18\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Conv2d(in_channels=256, out_channels=class_num, kernel_size=(13, 1), stride=1), # 20\n",
    "            nn.BatchNorm2d(num_features=class_num),\n",
    "            nn.ReLU(),  # *** 22 ***\n",
    "            )\n",
    "        self.container = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=448+class_num, out_channels=class_num, kernel_size=(1, 1), stride=(1, 1)),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        keep_features = []\n",
    "        for i, layer in enumerate(self.backbone.children()):\n",
    "            x = layer(x)   # 向前传递每一层\n",
    "            if i in [2, 6, 13, 22]: # [2, 4, 8, 11, 22]   # 对指定层的数据进行收集\n",
    "                keep_features.append(x)\n",
    "\n",
    "            global_context = []\n",
    "            for i, f in enumerate(keep_features):\n",
    "              # 为提取的层添加下采样\n",
    "                if i in [0, 1]:\n",
    "                    f = nn.AvgPool2d(kernel_size=5, stride=5)(f)\n",
    "                if i in [2]:\n",
    "                    f = nn.AvgPool2d(kernel_size=(4, 10), stride=(4, 2))(f)\n",
    "\n",
    "              # 这里的作用类似BN，可以更好进行训练，收敛速度更快\n",
    "                f_pow = torch.pow(f, 2)\n",
    "                f_mean = torch.mean(f_pow)\n",
    "                f = torch.div(f, f_mean)\n",
    "                global_context.append(f)\n",
    "\n",
    "        # 多尺度特征融合\n",
    "        x = torch.cat(global_context, 1)\n",
    "        x = self.container(x)\n",
    "        logits = torch.mean(x, dim=2)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OKD9MOHUwihl"
   },
   "source": [
    "# 数据集定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "VEXeHBl6v23Z"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# 自定义数据加载\n",
    "class PlateDataSet(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, target_transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.images = os.listdir(self.root_dir)\n",
    "        # 标签定义\n",
    "        self.labels = [\"京\", \"沪\", \"津\", \"渝\", \"冀\", \"晋\", \"蒙\", \"辽\", \"吉\", \"黑\", \"苏\", \"浙\", \"皖\", \"闽\", \"赣\", \"鲁\", \"豫\", \"鄂\", \"湘\", \"粤\", \"桂\",\n",
    "                 \"琼\", \"川\", \"贵\", \"云\", \"藏\", \"陕\", \"甘\", \"青\", \"宁\", \"新\", \"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"A\",\n",
    "                 \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"J\", \"K\", \"L\", \"M\", \"N\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\",\n",
    "                 \"Y\", \"Z\", \"-\"]\n",
    "\n",
    "        # CCPD中字符的位置\n",
    "        self.provinces = [\"皖\", \"沪\", \"津\", \"渝\", \"冀\", \"晋\", \"蒙\", \"辽\", \"吉\", \"黑\", \"苏\", \"浙\", \"京\", \"闽\", \"赣\", \"鲁\", \"豫\", \"鄂\", \"湘\", \"粤\", \"桂\", \"琼\", \"川\", \"贵\", \"云\", \"藏\", \"陕\", \"甘\", \"青\", \"宁\", \"新\", \"警\", \"学\", \"-\"]\n",
    "        self.alphabets = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W',\n",
    "                 'X', 'Y', 'Z', '-']\n",
    "        self.ads = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X',\n",
    "           'Y', 'Z', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '-']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "  \n",
    "\n",
    "  # 如果使用CCPD数据集，则使用如下代码\n",
    "    def __getitem__(self, index):\n",
    "        image_index = self.images[index]\n",
    "        img_path = os.path.join(self.root_dir, image_index)\n",
    "\n",
    "        # 只识别车牌，所以首先要把车牌给找到\n",
    "        img = Image.open(img_path)\n",
    "        # plt.imshow(img)\n",
    "        # plt.show()\n",
    "        anno_str = img_path.split(\"-\")\n",
    "        # print(anno_str)\n",
    "        # print(anno_str[2])\n",
    "        # 找到对应车牌位置\n",
    "        lt, rb = anno_str[2].split(\"_\")\n",
    "        lt = list(map(int, lt.split('&')))\n",
    "        rb = list(map(int, rb.split('&')))\n",
    "        img = img.crop((lt[0], lt[1], rb[0], rb[1]))\n",
    "#         plt.imshow(img)\n",
    "#         plt.show()\n",
    "#         label为车牌号\n",
    "#         print(anno_str[4])\n",
    "        label = list(map(int, anno_str[4].split('_')))\n",
    "        label_char = []\n",
    "        label_char.append(self.provinces[label[0]])\n",
    "        label_char.append(self.alphabets[label[1]])\n",
    "        for i in label[2:]:\n",
    "            label_char.append(self.ads[i])\n",
    "    # print(label_char)\n",
    "    # 与labels进行映射\n",
    "        labels = []\n",
    "        for i in range(len(label_char)):\n",
    "            labels.append(torch.tensor(self.labels.index(label_char[i])))\n",
    "        if self.transform:\n",
    "      # plt.imshow(img)\n",
    "      # plt.show()\n",
    "            img = self.transform(img)\n",
    "    # print(\"length: \", len(labels))\n",
    "        labels = torch.tensor(labels) # 将label转化为tensor\n",
    "        length = torch.tensor(len(labels))\n",
    "        return img, labels, length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "onYHlaQ68IBN",
    "outputId": "53d86a66-7db2-44d8-f9a6-54f5c8adac4b"
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "def collate_fn(batch):\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    lengths = []\n",
    "    for _, sample in enumerate(batch):\n",
    "        img, label, length = sample\n",
    "        imgs.append(img)\n",
    "        labels.extend(label)\n",
    "        lengths.append(length)\n",
    "    labels = np.asarray(labels).flatten().astype(np.float32)\n",
    "    lengths = torch.tensor(lengths)\n",
    "    return (torch.stack(imgs, 0), torch.from_numpy(labels), lengths)\n",
    "\n",
    "train_dataset = PlateDataSet('E:/test/licensePlateRecognition/content/license_plate/train/', \n",
    "                               transform=transforms.Compose([\n",
    "                                 transforms.Resize((24, 94)),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize(mean = (0.5, 0.5, 0.5), std = (0.5, 0.5, 0.5))\n",
    "                               ]))\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=4, collate_fn=collate_fn)\n",
    "x, y, z = iter(train_dataloader).next()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X82R8nEgxpnx"
   },
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ESfdImulxmZ6",
    "outputId": "b9c22b8b-87cd-4140-fdb6-3af7151fc6fd",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train\n",
    "import time\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "device = torch.device('cuda')\n",
    "weight_save_path = 'E:/test/licensePlateRecognition/content/LPRNet_Weights/'\n",
    "train_batch_size = 128\n",
    "test_batch_size = 120\n",
    "learning_rate = 1e-3\n",
    "max_epoch = 31\n",
    "save_interval = 3\n",
    "T_length = 18  # 最大8位车牌，每个真实标签前后都要有一个空白位占位\n",
    "load_pretrained_weights = False\n",
    "resume_epoch = 1\n",
    "pretrained_weights_path = '/content/drive/MyDrive/LPRNet_Weights/LPRNet__epoch_20.pth'\n",
    "\n",
    "train_dataset = PlateDataSet('E:/test/licensePlateRecognition/content/license_plate/train',\n",
    "                             transform=transforms.Compose([\n",
    "                                 transforms.Resize((24, 94)),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "                             ]))\n",
    "val_dataset = PlateDataSet('E:/test/licensePlateRecognition/content/license_plate/test',\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Resize((24, 94)),\n",
    "                               transforms.ToTensor()\n",
    "                           ]))\n",
    "\n",
    "\n",
    "def sparse_tuple_for_ctc(T_length, lengths):\n",
    "    input_lengths = []\n",
    "    target_lengths = []\n",
    "    for ch in lengths:\n",
    "        input_lengths.append(T_length)\n",
    "        target_lengths.append(ch)\n",
    "    return tuple(input_lengths), tuple(target_lengths)\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    lengths = []\n",
    "    for _, sample in enumerate(batch):\n",
    "        img, label, length = sample\n",
    "        imgs.append(img)\n",
    "        labels.extend(label)\n",
    "        lengths.append(length)\n",
    "    labels = np.asarray(labels).flatten().astype(np.float32)\n",
    "    lengths = torch.tensor(lengths)\n",
    "    return (torch.stack(imgs, 0), torch.from_numpy(labels), lengths)\n",
    "\n",
    "\n",
    "net = LPRNet(class_num=len(train_dataset.labels), dropout_rate=0.5).to(device)\n",
    "\n",
    "# 加载数据\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=train_batch_size, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset, shuffle=True, batch_size=test_batch_size, collate_fn=collate_fn)\n",
    "\n",
    "# 创建损失函数和优化器\n",
    "ctc_loss = nn.CTCLoss(blank=len(train_dataset.labels) - 1, reduction='mean')\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "# optimizer = torch.optim.RMSprop(net.parameters(), lr=learning_rate, alpha = 0.9, eps=1e-08,\n",
    "#                          momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "# 加载预训练权重\n",
    "if load_pretrained_weights:\n",
    "    net.load_state_dict(torch.load(pretrained_weights_path, map_location=device))\n",
    "    print(\"load pretrained model successful!\")\n",
    "else:\n",
    "    def xavier(param):\n",
    "        nn.init.xavier_uniform(param)\n",
    "\n",
    "\n",
    "    def weights_init(m):\n",
    "        for key in m.state_dict():\n",
    "            if key.split('.')[-1] == 'weight':\n",
    "                if 'conv' in key:\n",
    "                    nn.init.kaiming_normal_(m.state_dict()[key], mode='fan_out')\n",
    "                if 'bn' in key:\n",
    "                    m.state_dict()[key][...] = xavier(1)\n",
    "            elif key.split('.')[-1] == 'bias':\n",
    "                m.state_dict()[key][...] = 0.01\n",
    "\n",
    "\n",
    "    net.backbone.apply(weights_init)\n",
    "    net.container.apply(weights_init)\n",
    "    print(\"initial net weights successful!\")\n",
    "for epoch in range(resume_epoch, max_epoch):\n",
    "    print('starting epoch:',epoch)\n",
    "    if (epoch) != 0 and (epoch) % save_interval == 0:\n",
    "        torch.save(net.state_dict(), weight_save_path + 'LPRNet_' + '_epoch_' + repr(epoch) + '.pth')\n",
    "\n",
    "    net.train()\n",
    "    loss_val = 0\n",
    "    start_time = time.time()\n",
    "    for images, labels, lengths in train_dataloader:\n",
    "        images, labels, lengths = images.to(device), labels.to(device), lengths.to(device)\n",
    "        input_lengths, target_lengths = sparse_tuple_for_ctc(T_length, lengths)\n",
    "        # print(images.shape)\n",
    "        # print(labels.shape)\n",
    "        # print(lengths.shape)\n",
    "        logits = net(images)\n",
    "        log_probs = logits.permute(2, 0, 1)\n",
    "        log_probs = log_probs.log_softmax(2).requires_grad_()\n",
    "        optimizer.zero_grad()\n",
    "        loss = ctc_loss(log_probs, labels, input_lengths=input_lengths, target_lengths=target_lengths)\n",
    "        # print(loss.item())\n",
    "        if loss.item() == np.inf:\n",
    "            continue\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_val += loss.item()\n",
    "    end_time = time.time()\n",
    "    print('Epoch:' + repr(epoch) + ' || Total Loss: %f||' % (loss_val) +\n",
    "          'Batch time: %.4f sec. ||' % (end_time - start_time) + 'LR: %.8f' % (learning_rate))\n",
    "\n",
    "    # validation\n",
    "    if epoch % 3 == 0:\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            count = 0\n",
    "            Tp = 0\n",
    "            Tn_1 = 0\n",
    "            Tn_2 = 0\n",
    "            t1 = time.time()\n",
    "            for images, labels, lengths in val_dataloader:\n",
    "\n",
    "                images, labels, lengths = images.to(device), labels.to(device), lengths.to(device)\n",
    "                start = 0\n",
    "                targets = []\n",
    "                for length in lengths:\n",
    "                    label = labels[start:start + length]\n",
    "                    targets.append(label)\n",
    "                    start += length\n",
    "                prebs = net(images)\n",
    "                preb_labels = []\n",
    "                for i in range(prebs.shape[0]):\n",
    "                    preb = prebs[i, :, :]\n",
    "                    preb_label = []\n",
    "                    preb_label = preb.argmax(dim=0)\n",
    "                    no_repeat_blank_label = []\n",
    "                    pre_c = preb_label[0]\n",
    "                    if pre_c != len(val_dataset.labels) - 1:\n",
    "                        no_repeat_blank_label.append(pre_c)\n",
    "                    for c in preb_label:  # dropout repeate label and blank label\n",
    "                        if (pre_c == c) or (c == len(val_dataset.labels) - 1):\n",
    "                            if c == len(val_dataset.labels) - 1:\n",
    "                                pre_c = c\n",
    "                            continue\n",
    "                        no_repeat_blank_label.append(c)\n",
    "                        pre_c = c\n",
    "                    preb_labels.append(no_repeat_blank_label)\n",
    "\n",
    "                for i, label in enumerate(preb_labels):\n",
    "                    label = torch.tensor(label).to(device)\n",
    "                    targets[i] = targets[i].to(device)\n",
    "                    # print('================')\n",
    "                    # print(label)\n",
    "                    # print(targets[i])\n",
    "                    # print('================')\n",
    "                    if len(label) != len(targets[i]):\n",
    "                        Tn_1 += 1\n",
    "                        continue\n",
    "                    if targets[i].eq(label).all():\n",
    "                        Tp += 1\n",
    "                    else:\n",
    "                        Tn_2 += 1\n",
    "                count += 1\n",
    "\n",
    "            print(\"[Info] Validation Accuracy: {} [{}:{}:{}:{}]\".format(Tp / (Tp + Tn_1 + Tn_2), Tp, Tn_1, Tn_2,\n",
    "                                                                        (Tp + Tn_1 + Tn_2)))\n",
    "            t2 = time.time()\n",
    "            print(\"[Info] Validation Speed: {}s]\".format(t2 - t1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FeXXzV4oNWu5"
   },
   "source": [
    "# 测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c5wtqqCwPt8o"
   },
   "source": [
    "## 单张图片测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IksJ51b5CzDJ",
    "outputId": "0687e7ee-f5e2-4739-8877-59015844688f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load pretrained model successful!\n",
      "[tensor(12, device='cuda:0'), tensor(44, device='cuda:0'), tensor(44, device='cuda:0'), tensor(38, device='cuda:0'), tensor(33, device='cuda:0'), tensor(39, device='cuda:0'), tensor(36, device='cuda:0')]\n",
      "皖DD7285"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "device = torch.device('cuda')\n",
    "test_batch_size = 120\n",
    "T_length = 18  # 最大8位车牌，每个真实标签前后都要有一个空白位占位\n",
    "pretrained_weights_path = 'E:\\test\\licensePlateRecognition\\content\\LPRNet_Weights\\'\n",
    "\n",
    "labels = [\"京\", \"沪\", \"津\", \"渝\", \"冀\", \"晋\", \"蒙\", \"辽\", \"吉\", \"黑\", \"苏\", \"浙\", \"皖\", \"闽\", \"赣\", \"鲁\", \"豫\", \"鄂\", \"湘\", \"粤\", \"桂\",\n",
    "          \"琼\", \"川\", \"贵\", \"云\", \"藏\", \"陕\", \"甘\", \"青\", \"宁\", \"新\", \"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"A\",\n",
    "          \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"J\", \"K\", \"L\", \"M\", \"N\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\",\n",
    "          \"Y\", \"Z\", \"-\"]\n",
    "\n",
    "img_path = 'E:/test/licensePlateRecognition/content/test/3.jpg'\n",
    "preprocess_transform = transforms.Compose([\n",
    "    transforms.Resize((24, 94)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "def sparse_tuple_for_ctc(T_length, lengths):\n",
    "    input_lengths = []\n",
    "    target_lengths = []\n",
    "    for ch in lengths:\n",
    "        input_lengths.append(T_length)\n",
    "        target_lengths.append(ch)\n",
    "    return tuple(input_lengths), tuple(target_lengths)\n",
    "\n",
    "\n",
    "net = LPRNet(class_num=len(labels)).to(device)\n",
    "net.load_state_dict(torch.load(pretrained_weights_path, map_location=device))\n",
    "print(\"load pretrained model successful!\")\n",
    "img = Image.open(img_path).convert('RGB')\n",
    "img = preprocess_transform(img).to(device)\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    t1 = time.time()\n",
    "    start = 0\n",
    "    targets = []\n",
    "    img = img.unsqueeze(0)\n",
    "    prebs = net(img)\n",
    "    preb_labels = []\n",
    "    for i in range(prebs.shape[0]):\n",
    "        preb = prebs[i, :, :]\n",
    "        preb_label = []\n",
    "        preb_label = preb.argmax(dim=0)\n",
    "        no_repeat_blank_label = []\n",
    "        pre_c = preb_label[0]\n",
    "        if pre_c != len(labels) - 1:\n",
    "            no_repeat_blank_label.append(pre_c)\n",
    "        for c in preb_label:  # dropout repeate label and blank label\n",
    "            if (pre_c == c) or (c == len(labels) - 1):\n",
    "                if c == len(labels) - 1:\n",
    "                    pre_c = c\n",
    "                continue\n",
    "            no_repeat_blank_label.append(c)\n",
    "            pre_c = c\n",
    "        preb_labels.append(no_repeat_blank_label)\n",
    "    for i, label in enumerate(preb_labels):\n",
    "        # print('================')\n",
    "        print(label)\n",
    "#         print(targets[i])\n",
    "        # print('================')\n",
    "        for j in label:\n",
    "            print(labels[j], end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fIVxoBFDP7cV"
   },
   "source": [
    "## 多张图片测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OZNcJS9GP_DT",
    "outputId": "77c0cd76-441b-414f-fc60-b2b059b5acbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load pretrained model successful!\n",
      "[Info] Validation Accuracy: 0.8641534901658311 [26889:1240:2987:31116]\n",
      "[Info] Validation Speed: 421.1495382785797s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    lengths = []\n",
    "    for _, sample in enumerate(batch):\n",
    "        img, label, length = sample\n",
    "        imgs.append(img)\n",
    "        labels.extend(label)\n",
    "        lengths.append(length)\n",
    "    labels = np.asarray(labels).flatten().astype(np.float32)\n",
    "    lengths = torch.tensor(lengths)\n",
    "    return (torch.stack(imgs, 0), torch.from_numpy(labels), lengths)\n",
    "\n",
    "\n",
    "# 超参数定义\n",
    "test_batch_size = 120\n",
    "device = torch.device('cuda')\n",
    "pretrained_weights_path = 'E:/test/licensePlateRecognition/content/LPRNet_Weights/LPRNet__epoch_21_last.pth'\n",
    "\n",
    "test_dataset = PlateDataSet('E:/test/licensePlateRecognition/content/plates/test/',\n",
    "                            transform=transforms.Compose([\n",
    "                                transforms.Resize((24, 94)),\n",
    "                                transforms.ToTensor()\n",
    "                            ]))\n",
    "test_dataloader = DataLoader(test_dataset, shuffle=True, batch_size=test_batch_size, collate_fn=collate_fn)\n",
    "net = LPRNet(class_num=len(test_dataset.labels), dropout_rate=0.0).to(device)\n",
    "net.load_state_dict(torch.load(pretrained_weights_path, map_location=device))\n",
    "print(\"load pretrained model successful!\")\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    count = 0\n",
    "    Tp = 0\n",
    "    Tn_1 = 0\n",
    "    Tn_2 = 0\n",
    "    t1 = time.time()\n",
    "    for images, labels, lengths in val_dataloader:\n",
    "\n",
    "        images, labels, lengths = images.to(device), labels.to(device), lengths.to(device)\n",
    "        start = 0\n",
    "        targets = []\n",
    "        for length in lengths:\n",
    "            label = labels[start:start + length]\n",
    "            targets.append(label)\n",
    "            start += length\n",
    "        prebs = net(images)\n",
    "        preb_labels = []\n",
    "        for i in range(prebs.shape[0]):\n",
    "            preb = prebs[i, :, :]\n",
    "            preb_label = []\n",
    "            preb_label = preb.argmax(dim=0)\n",
    "            no_repeat_blank_label = []\n",
    "            pre_c = preb_label[0]\n",
    "            if pre_c != len(val_dataset.labels) - 1:\n",
    "                no_repeat_blank_label.append(pre_c)\n",
    "            for c in preb_label:  # dropout repeate label and blank label\n",
    "                if (pre_c == c) or (c == len(val_dataset.labels) - 1):\n",
    "                    if c == len(val_dataset.labels) - 1:\n",
    "                        pre_c = c\n",
    "                    continue\n",
    "                no_repeat_blank_label.append(c)\n",
    "                pre_c = c\n",
    "            preb_labels.append(no_repeat_blank_label)\n",
    "\n",
    "        for i, label in enumerate(preb_labels):\n",
    "            label = torch.tensor(label).to(device)\n",
    "            targets[i] = targets[i].to(device)\n",
    "            # print('================')\n",
    "            # print(label)\n",
    "            # print(targets[i])\n",
    "            # print('================')\n",
    "            if len(label) != len(targets[i]):\n",
    "                Tn_1 += 1\n",
    "                continue\n",
    "            if targets[i].eq(label).all():\n",
    "                Tp += 1\n",
    "            else:\n",
    "                Tn_2 += 1\n",
    "        count += 1\n",
    "\n",
    "    print(\"[Info] Validation Accuracy: {} [{}:{}:{}:{}]\".format(Tp / (Tp + Tn_1 + Tn_2), Tp, Tn_1, Tn_2,\n",
    "                                                                (Tp + Tn_1 + Tn_2)))\n",
    "    t2 = time.time()\n",
    "    print(\"[Info] Validation Speed: {}s]\".format(t2 - t1))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "车牌识别-CTC",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
